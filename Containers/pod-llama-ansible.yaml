apiVersion: v1
kind: Pod
metadata:
  name: llama-ansible-pod
spec:
  hostNetwork: true
  restartPolicy: Always
  containers:
    - name: llama-server
      image: ghcr.io/ggerganov/llama.cpp:server
      args: ["--model","/models/Qwen2.5-1.5B-Instruct-Q4_K_M.gguf",
             "--host","0.0.0.0","--port","8000",
             "--ctx-size","4096","--n-gpu-layers","0","--embedding"]
      volumeMounts:
        - name: models
          mountPath: /models
          readOnly: true
    - name: ansible-agent
      image: localhost/llama-ansible-agent:latest
      env:
        - name: MODEL_URL
          value: http://127.0.0.1:8000/v1
        - name: API_KEY
          value: sk-noauth
        - name: WORK_DIR
          value: /work
      volumeMounts:
        - name: sshkeys
          mountPath: /home/agent/.ssh
          readOnly: true
        - name: work
          mountPath: /work
  volumes:
    - name: models
      hostPath:
        path: /data/models
        type: Directory
    - name: sshkeys
      hostPath:
        path: /root/.ssh
        type: Directory
    - name: work
      hostPath:
        path: /data/agent-work
        type: DirectoryOrCreate
