apiVersion: v1
kind: Pod
metadata:
  name: llama-ansible-pod
spec:
  hostNetwork: true
  restartPolicy: Always
  network:
    - name: podman
  containers:
    - name: llama-server
      image: ghcr.io/ggerganov/llama.cpp:server
      args: ["--model","/models/data.guff",
             "--host","0.0.0.0","--port","8080",
             "--ctx-size","4096","--n-gpu-layers","0"]
      volumeMounts:
        - name: models
          mountPath: /models/model.guff
          readOnly: true
    - name: ansible-agent
      image: localhost/llama-ansible-agent:latest
      env:
        - name: MODEL_URL
          value: http://127.0.0.1:8080/v1
        - name: API_KEY
          value: sk-noauth
        - name: WORK_DIR
          value: /work
      volumeMounts:
        - name: sshkeys
          mountPath: /home/agent/.ssh
          readOnly: true
        - name: work
          mountPath: /work
      ports:
        - containerPort: 8082
          hostPort: 8082
  volumes:
    - name: models
      hostPath:
        path: /root/models/data.guff  ## model 파일이 있는 위치(호스트 컴퓨터)
        type: File
    - name: sshkeys
      hostPath:
        path: /root/.ssh
        type: Directory
    - name: work
      hostPath:
        path: /data/agent-work
        type: DirectoryOrCreate
